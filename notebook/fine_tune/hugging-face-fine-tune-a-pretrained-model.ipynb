{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "dict_keys(['train', 'test'])\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "print(type(dataset))\n",
    "print(dataset.keys())\n",
    "\n",
    "sub_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "sub_test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 3,\n",
       " 'text': \"I recently brough my car up to Edinburgh from home, where it had sat on the drive pretty much since I had left home to go to university.\\\\n\\\\nAs I'm sure you can imagine, it was pretty filthy, so I pulled up here expecting to shell out \\\\u00a35 or so for a crappy was that wouldnt really be that great.\\\\n\\\\nNeedless to say, when I realised that the cheapest was was \\\\u00a32, i was suprised and I was even more suprised when the car came out looking like a million dollars.\\\\n\\\\nVery impressive for \\\\u00a32, but thier prices can go up to around \\\\u00a36 - which I'm sure must involve so many polishes and waxes and cleans that dirt must be simply repelled from the body of your car, never getting dirty again.\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_train_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/650000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 650000/650000 [01:41<00:00, 6381.27 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:07<00:00, 6469.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(small_train_dataset[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-cased\", num_labels=5, torch_dtype=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.31116628646850586}]\n"
     ]
    }
   ],
   "source": [
    "result = classifier(\"This restaurant has excellent service and great food!\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **`TrainingArguments` å‚æ•°è¯¦è§£ï¼ˆé€šä¿—ç‰ˆï¼‰**\n",
    "\n",
    "`TrainingArguments` æ˜¯ Hugging Face Transformers åº“ä¸­æŽ§åˆ¶æ¨¡åž‹è®­ç»ƒçš„æ ¸å¿ƒé…ç½®ï¼Œç›´æŽ¥å†³å®šè®­ç»ƒé€Ÿåº¦ã€æ˜¾å­˜å ç”¨ã€æ¨¡åž‹æ•ˆæžœç­‰ã€‚ä»¥ä¸‹åˆ†æ¨¡å—ä»‹ç»æ‰€æœ‰é‡è¦å‚æ•°åŠå…¶å½±å“ï¼Œç”¨â€œðŸš€â€æ ‡æ³¨å¸¸è§é…ç½®åœºæ™¯ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### **ä¸€ã€åŸºç¡€è®­ç»ƒé…ç½®**\n",
    "#### 1. **`output_dir`**\n",
    "- **ä½œç”¨**ï¼šæ¨¡åž‹å’Œè®­ç»ƒæ—¥å¿—çš„ä¿å­˜è·¯å¾„ã€‚\n",
    "- **ç¤ºä¾‹**ï¼š`output_dir=\"./my_model\"` â†’ è®­ç»ƒåŽçš„æ¨¡åž‹ä¼šå­˜åœ¨ `my_model` æ–‡ä»¶å¤¹ã€‚\n",
    "- **æ³¨æ„**ï¼šè·¯å¾„è¦æå‰åˆ›å»ºå¥½ï¼Œå¦åˆ™å¯èƒ½æŠ¥é”™ã€‚\n",
    "\n",
    "#### 2. **`num_train_epochs`**\n",
    "- **ä½œç”¨**ï¼šè®­ç»ƒçš„æ€»è½®æ•°ï¼ˆæ‰€æœ‰æ•°æ®è¿‡ä¸€éç®—ä¸€è½®ï¼‰ã€‚\n",
    "- **å½±å“**ï¼š\n",
    "  - å€¼å¤ªå° â†’ æ¨¡åž‹æ²¡å­¦å®Œï¼Œæ•ˆæžœå·®ã€‚\n",
    "  - å€¼å¤ªå¤§ â†’ è¿‡æ‹Ÿåˆï¼ˆè®­ç»ƒé›†è¡¨çŽ°å¥½ï¼Œæµ‹è¯•é›†å·®ï¼‰ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šå¾®è°ƒä»»åŠ¡é€šå¸¸ 3-5 è½®ï¼Œé¢„è®­ç»ƒä»»åŠ¡ 10+ è½®ã€‚\n",
    "\n",
    "#### 3. **`per_device_train_batch_size`**\n",
    "- **ä½œç”¨**ï¼šæ¯ä¸ª GPU ä¸€æ¬¡å¤„ç†çš„æ ·æœ¬æ•°ã€‚\n",
    "- **å½±å“**ï¼š\n",
    "  - å€¼è¶Šå¤§ â†’ æ˜¾å­˜å ç”¨è¶Šé«˜ï¼Œè®­ç»ƒé€Ÿåº¦è¶Šå¿«ã€‚\n",
    "  - å€¼å¤ªå° â†’ æ˜¾å­˜ä¸è¶³æ—¶ä¼šæŠ¥é”™ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šæ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼ˆ24GB GPU å¯è®¾ 4-8ï¼‰ã€‚\n",
    "\n",
    "#### 4. **`gradient_accumulation_steps`**\n",
    "- **ä½œç”¨**ï¼šæ”’å¤šå°‘æ­¥çš„æ¢¯åº¦å†æ›´æ–°æ¨¡åž‹ï¼ˆç­‰æ•ˆæ‰©å¤§æ‰¹é‡å¤§å°ï¼‰ã€‚\n",
    "- **ç¤ºä¾‹**ï¼š`batch_size=2` + `gradient_accumulation=4` â†’ å®žé™…æ‰¹é‡=8ã€‚\n",
    "- **ðŸš€åœºæ™¯**ï¼šæ˜¾å­˜ä¸è¶³æ—¶ç”¨æ­¤å‚æ•°â€œæ¨¡æ‹Ÿâ€å¤§æ‰¹é‡è®­ç»ƒã€‚\n",
    "\n",
    "#### 5. **`fp16` / `bf16`**\n",
    "- **ä½œç”¨**ï¼šå¼€å¯åŠç²¾åº¦è®­ç»ƒï¼ˆ16 ä½æµ®ç‚¹æ•°ï¼‰ï¼ŒèŠ‚çœæ˜¾å­˜å¹¶åŠ é€Ÿã€‚\n",
    "  - `fp16`ï¼šé€‚åˆ NVIDIA GPUã€‚\n",
    "  - `bf16`ï¼šé€‚åˆ AMD GPU æˆ– TPUã€‚\n",
    "- **æ³¨æ„**ï¼šå¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®šï¼ˆéƒ¨åˆ†æ¨¡åž‹éœ€å…³é—­ï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### **äºŒã€ä¼˜åŒ–å™¨ä¸Žå­¦ä¹ çŽ‡**\n",
    "#### 6. **`learning_rate`**\n",
    "- **ä½œç”¨**ï¼šå­¦ä¹ æ­¥é•¿ï¼Œå†³å®šå‚æ•°æ›´æ–°å¹…åº¦ã€‚\n",
    "- **å½±å“**ï¼š\n",
    "  - å¤ªå¤§ â†’ è®­ç»ƒéœ‡è¡ç”šè‡³å´©æºƒã€‚\n",
    "  - å¤ªå° â†’ æ”¶æ•›æ…¢ï¼Œæ•ˆæžœå·®ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šé¢„è®­ç»ƒç”¨ `1e-4`ï¼Œå¾®è°ƒç”¨ `2e-5` ~ `5e-5`ã€‚\n",
    "\n",
    "#### 7. **`weight_decay`**\n",
    "- **ä½œç”¨**ï¼šæƒé‡è¡°å‡ï¼ˆL2 æ­£åˆ™åŒ–ï¼‰ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚\n",
    "- **å½±å“**ï¼šå€¼è¶Šå¤§ â†’ æ¨¡åž‹å‚æ•°è¶Šå°ï¼Œæ³›åŒ–æ€§è¶Šå¼ºï¼Œä½†å¯èƒ½æ¬ æ‹Ÿåˆã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šé»˜è®¤ `0.01`ï¼Œå¤æ‚ä»»åŠ¡å¯è°ƒä½Žè‡³ `0.001`ã€‚\n",
    "\n",
    "#### 8. **`optim`**\n",
    "- **ä½œç”¨**ï¼šé€‰æ‹©ä¼˜åŒ–å™¨ç±»åž‹ã€‚\n",
    "- **å¯é€‰å€¼**ï¼š\n",
    "  - `\"adamw_torch\"`ï¼ˆé»˜è®¤ï¼‰ï¼šé€‚åˆå¤§å¤šæ•°åœºæ™¯ã€‚\n",
    "  - `\"adafactor\"`ï¼šçœæ˜¾å­˜ä½†æ”¶æ•›æ…¢ã€‚\n",
    "  - `\"sgd\"`ï¼šç®€å•ä»»åŠ¡å¯ç”¨ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šæ— ç‰¹æ®Šéœ€æ±‚ä¿æŒé»˜è®¤ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### **ä¸‰ã€è¯„ä¼°ä¸Žä¿å­˜**\n",
    "#### 9. **`evaluation_strategy`**\n",
    "- **ä½œç”¨**ï¼šä½•æ—¶è¿›è¡Œè¯„ä¼°ã€‚\n",
    "- **å¯é€‰å€¼**ï¼š\n",
    "  - `\"no\"`ï¼šä¸è¯„ä¼°ã€‚\n",
    "  - `\"steps\"`ï¼šæŒ‰æ­¥æ•°è¯„ä¼°ã€‚\n",
    "  - `\"epoch\"`ï¼šæ¯è½®ç»“æŸæ—¶è¯„ä¼°ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šéªŒè¯é›†è¾ƒå¤§æ—¶ç”¨ `\"epoch\"`ï¼Œå¦åˆ™ç”¨ `\"steps\"`ã€‚\n",
    "\n",
    "#### 10. **`eval_steps`**\n",
    "- **ä½œç”¨**ï¼šæ¯è®­ç»ƒå¤šå°‘æ­¥è¯„ä¼°ä¸€æ¬¡ï¼ˆéœ€ `evaluation_strategy=\"steps\"`ï¼‰ã€‚\n",
    "- **ç¤ºä¾‹**ï¼š`eval_steps=500` â†’ æ¯ 500 æ­¥éªŒè¯ä¸€æ¬¡ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šæ ¹æ®æ€»æ­¥æ•°è°ƒæ•´ï¼ˆå¦‚æ€»æ­¥ 5000 â†’ è®¾ 500ï¼‰ã€‚\n",
    "\n",
    "#### 11. **`save_strategy`**\n",
    "- **ä½œç”¨**ï¼šä½•æ—¶ä¿å­˜æ¨¡åž‹ã€‚\n",
    "- **å¯é€‰å€¼**ï¼šåŒ `evaluation_strategy`ã€‚\n",
    "- **ðŸš€æŠ€å·§**ï¼šè®¾ä¸ºä¸Ž `evaluation_strategy` ç›¸åŒï¼Œæ–¹ä¾¿ä¿å­˜æœ€ä½³æ¨¡åž‹ã€‚\n",
    "\n",
    "#### 12. **`save_total_limit`**\n",
    "- **ä½œç”¨**ï¼šæœ€å¤šä¿å­˜å¤šå°‘ä¸ªæ¨¡åž‹æ£€æŸ¥ç‚¹ã€‚\n",
    "- **ç¤ºä¾‹**ï¼š`save_total_limit=3` â†’ åªä¿ç•™æœ€æ–°çš„ 3 ä¸ªæ¨¡åž‹ï¼Œè‡ªåŠ¨åˆ é™¤æ—§çš„ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šè®¾ä¸º 2-3ï¼Œé¿å…å æ»¡ç£ç›˜ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### **å››ã€å­¦ä¹ çŽ‡è°ƒåº¦ä¸Žé¢„çƒ­**\n",
    "#### 13. **`lr_scheduler_type`**\n",
    "- **ä½œç”¨**ï¼šå­¦ä¹ çŽ‡è°ƒæ•´ç­–ç•¥ã€‚\n",
    "- **å¯é€‰å€¼**ï¼š\n",
    "  - `\"linear\"`ï¼ˆé»˜è®¤ï¼‰ï¼šçº¿æ€§è¡°å‡ã€‚\n",
    "  - `\"cosine\"`ï¼šä½™å¼¦é€€ç«ï¼Œé€‚åˆé•¿æ—¶é—´è®­ç»ƒã€‚\n",
    "  - `\"constant\"`ï¼šå›ºå®šå­¦ä¹ çŽ‡ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šå¾®è°ƒç”¨ `\"linear\"`ï¼Œé¢„è®­ç»ƒç”¨ `\"cosine\"`ã€‚\n",
    "\n",
    "#### 14. **`warmup_steps`** / `warmup_ratio`\n",
    "- **ä½œç”¨**ï¼šå­¦ä¹ çŽ‡é¢„çƒ­æ­¥æ•°ï¼ˆå‰æœŸé€æ­¥å¢žåŠ å­¦ä¹ çŽ‡ï¼‰ã€‚\n",
    "- **å½±å“**ï¼šé¿å…åˆæœŸå¤§å­¦ä¹ çŽ‡ç ´åé¢„è®­ç»ƒæƒé‡ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šè®¾ `warmup_ratio=0.1`ï¼ˆé¢„çƒ­ 10% çš„æ€»æ­¥æ•°ï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### **äº”ã€æ—¥å¿—ä¸Žè°ƒè¯•**\n",
    "#### 15. **`logging_dir`** / `logging_steps`\n",
    "- **ä½œç”¨**ï¼šæ—¥å¿—ä¿å­˜è·¯å¾„å’Œè®°å½•é¢‘çŽ‡ã€‚\n",
    "- **ç¤ºä¾‹**ï¼š`logging_steps=10` â†’ æ¯ 10 æ­¥è®°å½•ä¸€æ¬¡æŸå¤±ã€‚\n",
    "- **ðŸš€æŠ€å·§**ï¼šç”¨ TensorBoard æŸ¥çœ‹æ—¥å¿—ï¼š`tensorboard --logdir=./logs`ã€‚\n",
    "\n",
    "#### 16. **`report_to`**\n",
    "- **ä½œç”¨**ï¼šæ—¥å¿—ä¸ŠæŠ¥å¹³å°ã€‚\n",
    "- **å¯é€‰å€¼**ï¼š`\"tensorboard\"`ï¼ˆé»˜è®¤ï¼‰ã€`\"wandb\"`ï¼ˆWeights & Biasesï¼‰ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šæœ¬åœ°è°ƒè¯•ç”¨ `\"tensorboard\"`ï¼Œå›¢é˜Ÿåä½œç”¨ `\"wandb\"`ã€‚\n",
    "\n",
    "#### 17. **`dataloader_num_workers`**\n",
    "- **ä½œç”¨**ï¼šæ•°æ®åŠ è½½çš„å¹¶è¡Œè¿›ç¨‹æ•°ã€‚\n",
    "- **å½±å“**ï¼šå€¼è¶Šå¤§ â†’ æ•°æ®åŠ è½½è¶Šå¿«ï¼Œä½†å ç”¨æ›´å¤š CPU å†…å­˜ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šè®¾ä¸º CPU æ ¸å¿ƒæ•°çš„ 70%ï¼ˆå¦‚ 8 æ ¸ â†’ è®¾ 6ï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### **å…­ã€æ¢å¤è®­ç»ƒä¸Žè®¾å¤‡ç®¡ç†**\n",
    "#### 18. **`resume_from_checkpoint`**\n",
    "- **ä½œç”¨**ï¼šä»ŽæŒ‡å®šæ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚\n",
    "- **ç¤ºä¾‹**ï¼š`resume_from_checkpoint=\"./my_model/checkpoint-500\"`ã€‚\n",
    "- **ðŸš€åœºæ™¯**ï¼šè®­ç»ƒæ„å¤–ä¸­æ–­åŽç»§ç»­è®­ç»ƒã€‚\n",
    "\n",
    "#### 19. **`gradient_checkpointing`**\n",
    "- **ä½œç”¨**ï¼šå¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œç”¨æ—¶é—´æ¢æ˜¾å­˜ã€‚\n",
    "- **å½±å“**ï¼šæ˜¾å­˜å‡å°‘ 60%ï¼Œä½†è®­ç»ƒé€Ÿåº¦ä¸‹é™ 20%ã€‚\n",
    "- **ðŸš€æŽ¨è**ï¼šæ˜¾å­˜ä¸è¶³æ—¶å¼€å¯ï¼ˆå¦‚è®­ç»ƒ 10B+ æ¨¡åž‹ï¼‰ã€‚\n",
    "\n",
    "#### 20. **`device_map`**\n",
    "- **ä½œç”¨**ï¼šæŒ‡å®šæ¨¡åž‹åŠ è½½åˆ°å“ªäº›è®¾å¤‡ï¼ˆGPU/CPUï¼‰ã€‚\n",
    "- **ç¤ºä¾‹**ï¼š`device_map=\"auto\"` â†’ è‡ªåŠ¨åˆ†é…æ¨¡åž‹å±‚åˆ°å¯ç”¨ GPUã€‚\n",
    "- **ðŸš€æ³¨æ„**ï¼šéœ€å®‰è£… `accelerate` åº“ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### **å®Œæ•´æ€»ç»“è¡¨æ ¼**\n",
    "| **å‚æ•°** | **å¸¸è§å€¼** | **æ ¸å¿ƒå½±å“** | **é€‚ç”¨åœºæ™¯** |\n",
    "|----------|------------|--------------|--------------|\n",
    "| `per_device_train_batch_size` | 2-8 | æ˜¾å­˜å ç”¨ vs é€Ÿåº¦ | æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´ |\n",
    "| `gradient_accumulation_steps` | 4-8 | æ¨¡æ‹Ÿå¤§æ‰¹é‡è®­ç»ƒ | æ˜¾å­˜ä¸è¶³æ—¶æ‰©å¤§æ‰¹é‡ |\n",
    "| `learning_rate` | 2e-5 ~ 5e-5 | æ”¶æ•›é€Ÿåº¦ vs ç¨³å®šæ€§ | å¾®è°ƒä»»åŠ¡å¸¸ç”¨ |\n",
    "| `fp16` | `True` | çœæ˜¾å­˜ + åŠ é€Ÿ | NVIDIA GPU å¿…å¼€ |\n",
    "| `warmup_steps` | æ€»æ­¥æ•°çš„ 10% | é¿å…åˆæœŸéœ‡è¡ | æ‰€æœ‰è®­ç»ƒä»»åŠ¡ |\n",
    "| `save_total_limit` | 2-3 | æŽ§åˆ¶ç£ç›˜å ç”¨ | é•¿æœŸè®­ç»ƒä»»åŠ¡ |\n",
    "\n",
    "---\n",
    "\n",
    "### **é…ç½®ç¤ºä¾‹**\n",
    "```python\n",
    "# å•å¡ 24GB GPU å¾®è°ƒé…ç½®ï¼ˆå¦‚ LLaMA-7Bï¼‰\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,  # å®žé™…æ‰¹é‡=16\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    warmup_steps=50,\n",
    "    weight_decay=0.01,\n",
    "    optim=\"adamw_torch\",\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", \n",
    "                                  eval_strategy=\"epoch\",\n",
    "                                  num_train_epochs=0.01,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:15, Epoch 0.02/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 75/125 01:53 < 01:16, 0.65 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/transformers/trainer.py:2639\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2639\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2643\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/transformers/trainer.py:3085\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3083\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 3085\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3086\u001b[0m     is_new_best_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_best_metric(metrics\u001b[38;5;241m=\u001b[39mmetrics, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   3088\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n",
      "File \u001b[0;32m~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/transformers/trainer.py:3039\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 3039\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3040\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   3042\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/transformers/trainer.py:4105\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4102\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4104\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4105\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4106\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   4109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   4110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4113\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4115\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/transformers/trainer.py:4321\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4319\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mpad_across_processes(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m   4320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4321\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4323\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n",
      "File \u001b[0;32m~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/accelerate/accelerator.py:2683\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpad_across_processes\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2651\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2652\u001b[0m \u001b[38;5;124;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;124;03m    they can safely be gathered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/accelerate/utils/operations.py:408\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DistributedOperationException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    410\u001b[0m         operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/accelerate/utils/operations.py:678\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    675\u001b[0m     new_tensor[indices] \u001b[38;5;241m=\u001b[39m tensor\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_tensor\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_pad_across_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/accelerate/utils/operations.py:126\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    118\u001b[0m         {\n\u001b[1;32m    119\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         }\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/accelerate/utils/operations.py:658\u001b[0m, in \u001b[0;36mpad_across_processes.<locals>._pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    655\u001b[0m     dim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tensor\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# Gather all sizes\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    659\u001b[0m sizes \u001b[38;5;241m=\u001b[39m gather(size)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# Then pad to the maximum size\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"test_trainer\")\n",
    "tokenizer.save_pretrained(\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
