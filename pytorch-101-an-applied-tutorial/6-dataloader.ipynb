{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        current_sample = self.data[idx, :]\n",
    "        current_target = self.targets[idx]\n",
    "        return {\n",
    "            \"sample\": torch.tensor(current_sample, dtype=torch.float),\n",
    "            \"target\": torch.tensor(current_target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = make_classification(n_samples=1000, n_features=20, n_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': tensor([-0.2690,  0.5073,  0.5369,  1.0548, -0.8478,  0.0588, -0.9053, -1.3440,\n",
       "         -0.1009, -0.7667,  1.0595, -0.6486,  0.8761,  1.0113,  1.3396,  0.9682,\n",
       "         -0.6845, -0.1543, -0.5683,  0.8647]),\n",
       " 'target': tensor(1)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0m_T_co\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_sampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcollate_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0m_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdrop_last\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mworker_init_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmultiprocessing_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprefetch_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpersistent_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0min_order\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
      "\n",
      "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      "iterable-style datasets with single- or multi-process loading, customizing\n",
      "loading order and optional automatic batching (collation) and memory pinning.\n",
      "\n",
      "See :py:mod:`torch.utils.data` documentation page for more details.\n",
      "\n",
      "Args:\n",
      "    dataset (Dataset): dataset from which to load the data.\n",
      "    batch_size (int, optional): how many samples per batch to load\n",
      "        (default: ``1``).\n",
      "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      "        at every epoch (default: ``False``).\n",
      "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
      "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      "        returns a batch of indices at a time. Mutually exclusive with\n",
      "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      "        and :attr:`drop_last`.\n",
      "    num_workers (int, optional): how many subprocesses to use for data\n",
      "        loading. ``0`` means that the data will be loaded in the main process.\n",
      "        (default: ``0``)\n",
      "    collate_fn (Callable, optional): merges a list of samples to form a\n",
      "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
      "        map-style dataset.\n",
      "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      "        into device/CUDA pinned memory before returning them.  If your data elements\n",
      "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      "        see the example below.\n",
      "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
      "        the size of dataset is not divisible by the batch size, then the last batch\n",
      "        will be smaller. (default: ``False``)\n",
      "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      "        from workers. Should always be non-negative. (default: ``0``)\n",
      "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      "        input, after seeding and before data loading. (default: ``None``)\n",
      "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
      "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
      "        be used. (default: ``None``)\n",
      "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
      "        ``base_seed`` for workers. (default: ``None``)\n",
      "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      "        in advance by each worker. ``2`` means there will be a total of\n",
      "        2 * num_workers batches prefetched across all workers. (default value depends\n",
      "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      "        Otherwise, if value of ``num_workers > 0`` default is ``2``).\n",
      "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
      "        the worker processes after a dataset has been consumed once. This allows to\n",
      "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
      "        ``True``.\n",
      "    in_order (bool, optional): If ``False``, the data loader will not enforce that batches\n",
      "        are returned in a first-in, first-out order. Only applies when ``num_workers > 0``. (default: ``True``)\n",
      "\n",
      "\n",
      ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      "             cannot be an unpicklable object, e.g., a lambda function. See\n",
      "             :ref:`multiprocessing-best-practices` on more details related\n",
      "             to multiprocessing in PyTorch.\n",
      "\n",
      ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
      "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
      "             loading to avoid duplicate data.\n",
      "\n",
      "             However, if sharding results in multiple workers having incomplete last batches,\n",
      "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      "             cases in general.\n",
      "\n",
      "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
      "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
      "             `Multi-process data loading`_.\n",
      "\n",
      ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
      "\n",
      ".. warning:: Setting `in_order` to `False` can harm reproducibility and may lead to a skewed data\n",
      "             distribution being fed to the trainer in cases with imbalanced data.\n",
      "\n",
      ".. _multiprocessing context:\n",
      "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
      "\u001b[0;31mFile:\u001b[0m           ~/workspace/project/interview/llm/grokking-llm/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': tensor([[-0.2690,  0.5073,  0.5369,  1.0548, -0.8478,  0.0588, -0.9053, -1.3440,\n",
      "         -0.1009, -0.7667,  1.0595, -0.6486,  0.8761,  1.0113,  1.3396,  0.9682,\n",
      "         -0.6845, -0.1543, -0.5683,  0.8647],\n",
      "        [ 1.6825,  1.3622, -1.9465,  0.0533, -1.4350, -0.6504, -2.3583, -1.0734,\n",
      "         -0.6125, -0.0439,  1.2209, -0.4343, -0.8557,  0.1565,  1.1897,  1.7761,\n",
      "          2.1977, -0.3873, -0.4120, -1.7711],\n",
      "        [-0.2458, -2.0439,  0.9142,  0.2754, -0.1716, -0.1332, -0.5049, -1.0783,\n",
      "          1.0374, -0.9152,  0.4344, -0.8055,  1.1963,  0.7411,  1.5739,  1.2661,\n",
      "         -0.9552,  0.4148, -0.9362, -0.2174],\n",
      "        [-1.5718, -0.1362,  2.2394, -0.2030,  0.2508,  1.2961, -0.5979, -0.6828,\n",
      "         -0.0735,  0.6507, -0.4680, -0.8603,  1.3244,  0.7774, -0.6317, -0.0170,\n",
      "          1.3565,  0.2599,  0.2785,  1.2474]]), 'target': tensor([1, 1, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    for data in train_loader:\n",
    "        x = data[\"sample\"]\n",
    "        y = data[\"target\"]\n",
    "        # outputs = model(x, y)\n",
    "        # loss = ...\n",
    "        # loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
